# Dennis Zang, 704766877, Homework 1
# -*- coding: utf-8 -*-
"""Fall2020_CS146_HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13felLh8fxcTKasBhjEmFvwvKggJQi59E
"""

import sys

# To add your own Drive Run this cell.
from google.colab import drive
drive.mount('/content/drive')

# Please append your own directory after â€˜/content/drive/My Drive/'
# where you have nutil.py and adult_subsample.csv
### ========== TODO : START ========== ###
# for example: sys.path += ['/content/drive/My Drive/Fall2020-CS146-HW1'] 
sys.path += ['/content/drive/My Drive/Fall2020-CS146-HW1']
### ========== TODO : END ========== ###

from nutil import *

# Use only the provided packages!
import math
import csv

from collections import Counter

from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit

######################################################################
# Immutatble classes
######################################################################

class Classifier(object) :
    """
    Classifier interface.
    """

    def fit(self, X, y):
        raise NotImplementedError()

    def predict(self, X):
        raise NotImplementedError()


class MajorityVoteClassifier(Classifier) :

    def __init__(self) :
        """
        A classifier that always predicts the majority class.

        Attributes
        --------------------
            prediction_ -- majority class
        """
        self.prediction_ = None

    def fit(self, X, y) :
        """
        Build a majority vote classifier from the training set (X, y).

        Parameters
        --------------------
            X    -- numpy array of shape (n,d), samples
            y    -- numpy array of shape (n,), target classes

        Returns
        --------------------
            self -- an instance of self
        """
        majority_val = Counter(y).most_common(1)[0][0]
        self.prediction_ = majority_val
        return self

    def predict(self, X) :
        """
        Predict class values.

        Parameters
        --------------------
            X    -- numpy array of shape (n,d), samples

        Returns
        --------------------
            y    -- numpy array of shape (n,), predicted classes
        """
        if self.prediction_ is None :
            raise Exception("Classifier not initialized. Perform a fit first.")

        n,d = X.shape
        y = [self.prediction_] * n
        return y

######################################################################
# Mutatble classes
######################################################################

class RandomClassifier(Classifier) :

    def __init__(self) :
        """
        A classifier that predicts according to the distribution of the classes.

        Attributes
        --------------------
            probabilities_ -- class distribution dict (key = class, val = probability of class)
        """
        self.probabilities_ = None

    def fit(self, X, y) :
        """
        Build a random classifier from the training set (X, y).

        Parameters
        --------------------
            X    -- numpy array of shape (n,d), samples
            y    -- numpy array of shape (n,), target classes

        Returns
        --------------------
            self -- an instance of self
        """

        ### ========== TODO : START ========== ###
        # part b: set self.probabilities_ according to the training set
        self.probabilities_ = {}
        numSamples = y.shape[0]
        if (y.ndim == 1):
          countObj = Counter(y)
          self.probabilities_[0] = float(countObj[1]) / float(numSamples) 
        else:
          for col in range(y.shape[1]):
            countObj = Counter(y[:,col])
            self.probabilities_[col] = float(countObj[1]) / float(numSamples)
        # implementation assumes binary random variable
        ### ========== TODO : END ========== ###

        return self

    def predict(self, X, seed=1234) :
        """
        Predict class values.

        Parameters
        --------------------
            X    -- numpy array of shape (n,d), samples
            seed -- integer, random seed

        Returns
        --------------------
            y    -- numpy array of shape (n,), predicted classes
        """
        if self.probabilities_ is None :
            raise Exception("Classifier not initialized. Perform a fit first.")
        np.random.seed(seed)

        ### ========== TODO : START ========== ###
        # part b: predict the class for each test example
        # hint: use np.random.choice (be careful of the parameters)
        np.random.seed(seed)
        y = np.zeros([X.shape[0], len(self.probabilities_)])
        for element in range(y.shape[0]):
          for key in self.probabilities_:
            y[element][key] = np.random.choice(a = [0, 1], size = 1, p = [1 - self.probabilities_[key], self.probabilities_[key]])
        ### ========== TODO : END ========== ###

        return y

######################################################################
# Immutatble functions
######################################################################

def plot_histograms(X, y, Xnames, yname) :
    n,d = X.shape  # n = number of examples, d =  number of features
    fig = plt.figure(figsize=(20,15))
    ncol = 3
    nrow = d // ncol + 1
    for i in range(d) :
        fig.add_subplot (nrow,ncol,i+1)
        data, bins, align, labels = plot_histogram(X[:,i], y, Xname=Xnames[i], yname=yname, show = False)
        n, bins, patches = plt.hist(data, bins=bins, align=align, alpha=0.5, label=labels)
        plt.xlabel(Xnames[i])
        plt.ylabel('Frequency')
        plt.legend() #plt.legend(loc='upper left')

    plt.savefig ('histograms.pdf')


def plot_histogram(X, y, Xname, yname, show = True) :
    """
    Plots histogram of values in X grouped by y.

    Parameters
    --------------------
        X     -- numpy array of shape (n,d), feature values
        y     -- numpy array of shape (n,), target classes
        Xname -- string, name of feature
        yname -- string, name of target
    """

    # set up data for plotting
    targets = sorted(set(y))
    data = []; labels = []
    for target in targets :
        features = [X[i] for i in range(len(y)) if y[i] == target]
        data.append(features)
        labels.append('%s = %s' % (yname, target))

    # set up histogram bins
    features = set(X)
    nfeatures = len(features)
    test_range = list(range(int(math.floor(min(features))), int(math.ceil(max(features)))+1))
    if nfeatures < 10 and sorted(features) == test_range:
        bins = test_range + [test_range[-1] + 1] # add last bin
        align = 'left'
    else :
        bins = 10
        align = 'mid'

    # plot
    if show == True:
        plt.figure()
        n, bins, patches = plt.hist(data, bins=bins, align=align, alpha=0.5, label=labels)
        plt.xlabel(Xname)
        plt.ylabel('Frequency')
        plt.legend() #plt.legend(loc='upper left')
        plt.show()

    return data, bins, align, labels

######################################################################
# Mutatble functions
######################################################################

def error(clf, X, y, ntrials=100, test_size=0.2) :
    """
    Computes the classifier error over a random split of the data,
    averaged over ntrials runs.

    Parameters
    --------------------
        clf         -- classifier
        X           -- numpy array of shape (n,d), features values
        y           -- numpy array of shape (n,), target classes
        ntrials     -- integer, number of trials

    Returns
    --------------------
        train_error -- float, training error
        test_error  -- float, test error
        f1_score    -- float, test "micro" averaged f1 score
    """

    ### ========== TODO : START ========== ###
    # compute cross-validation error using StratifiedShuffleSplit over ntrials
    # hint: use train_test_split (be careful of the parameters)
    clf.fit(X, y)
    train_error = 0.0
    test_error = 0.0
    f1_score = 0.0
    S = StratifiedShuffleSplit(n_splits = ntrials, test_size = test_size, random_state = 0)           # used as given in official specs
    for trainIndex, testIndex in S.split(X, y):                                                       # for each set of training and testing data (given as indices)
      trainX, testX = X[trainIndex], X[testIndex]                                                     # get the training and testing data
      trainY, testY = y[trainIndex], y[testIndex]
      clf.fit(trainX, trainY)                                                                         # fit to the given classifier
      y_predTrain = clf.predict(trainX)                                                               # predict using both training and test data for both errors
      y_predTest = clf.predict(testX)
      train_error = train_error + (1 - metrics.accuracy_score(trainY, y_predTrain, normalize=True))   # calculate errors and store them in a total
      test_error = test_error + (1 - metrics.accuracy_score(testY, y_predTest, normalize=True))
      f1_score = f1_score + metrics.f1_score(testY, y_predTest, average = 'micro')
    train_error = train_error / ntrials                                                               # take the average of the totals for the average errors
    test_error = test_error / ntrials
    f1_score = f1_score / ntrials
    print('\t-- train_error: %.3f' % train_error)
    print('\t-- test_error: %.3f' % test_error)
    print('\t-- f1_score: %.3f' % f1_score)
    ### ========== TODO : END ========== ###

    return train_error, test_error, f1_score

######################################################################
# Immutatble functions
######################################################################


def write_predictions(y_pred, filename, yname=None) :
    """Write out predictions to csv file."""
    out = open(filename, 'wb')
    f = csv.writer(out)
    if yname :
        f.writerow([yname])
    f.writerows(list(zip(y_pred)))
    out.close()

######################################################################
# main
######################################################################

def main():
    
    
    
    # load adult_subsample dataset with correct file path
    ### ========== TODO : START ========== ###
    data_file =  "/content/drive/My Drive/Fall2020-CS146-HW1/adult_subsample.csv"
    ### ========== TODO : END ========== ###
    



    data = load_data(data_file, header=1, predict_col=-1)

    X = data.X; Xnames = data.Xnames
    y = data.y; yname = data.yname
    n,d = X.shape  # n = number of examples, d =  number of features

    

    plt.figure()
    #========================================
    # part a: plot histograms of each feature
    print('Plotting...')
    plot_histograms (X, y, Xnames=Xnames, yname=yname)
    




    ### ========== TODO : START ========== ###
    # part i: Preprocess X (e.g., normalize)
    X = StandardScaler().fit_transform(X)
    ### ========== TODO : END ========== ###




    #========================================
    # train Majority Vote classifier on data
    print('Classifying using Majority Vote...')
    clf = MajorityVoteClassifier() # create MajorityVote classifier, which includes all model parameters
    clf.fit(X, y)                  # fit training data using the classifier
    y_pred = clf.predict(X)        # take the classifier and run it on the training data
    train_error = 1 - metrics.accuracy_score(y, y_pred, normalize=True)
    print('\t-- training error: %.3f' % train_error)





    ### ========== TODO : START ========== ###
    # part b: evaluate training error of Random classifier
    print('Classifying using Random...')
    randClf = RandomClassifier()                                                  # standard usage of classifier
    randClf.fit(X, y)
    y_predRand = randClf.predict(X)
    randTrain_error = 1 - metrics.accuracy_score(y, y_predRand, normalize=True)
    print('\t-- training error: %.3f' % randTrain_error)
    ### ========== TODO : END ========== ###





    ### ========== TODO : START ========== ###
    # part c: evaluate training error of Decision Tree classifier
    print('Classifying using Decision Tree...')
    dtClassifier = DecisionTreeClassifier(criterion='entropy')                    # standard usage of classifier
    dtClassifier.fit(X, y)
    y_predDT = dtClassifier.predict(X)
    dtTrain_error = 1 - metrics.accuracy_score(y, y_predDT, normalize=True)
    print('\t-- training error: %.3f' % dtTrain_error)
    ### ========== TODO : END ========== ###






    ### ========== TODO : START ========== ###
    # part d: evaluate training error of k-Nearest Neighbors classifier
    # use k = 3, 5, 7 for n_neighbors
    print('Classifying using k-Nearest Neighbors...')
    knn3Classifier = KNeighborsClassifier(n_neighbors = 3)                        # standard usage of classifer, but repeated thrice for each value of k
    knn5Classifier = KNeighborsClassifier(n_neighbors = 5)
    knn7Classifier = KNeighborsClassifier(n_neighbors = 7)
    knn3Classifier.fit(X, y)
    knn5Classifier.fit(X, y)
    knn7Classifier.fit(X, y)
    y_predKNN3 = knn3Classifier.predict(X)
    y_predKNN5 = knn5Classifier.predict(X)
    y_predKNN7 = knn7Classifier.predict(X)
    knn3Train_error = 1 - metrics.accuracy_score(y, y_predKNN3, normalize=True)
    knn5Train_error = 1 - metrics.accuracy_score(y, y_predKNN5, normalize=True)
    knn7Train_error = 1 - metrics.accuracy_score(y, y_predKNN7, normalize=True)
    print('\t-- training error: %.3f' % knn3Train_error)
    print('\t-- training error: %.3f' % knn5Train_error)
    print('\t-- training error: %.3f' % knn7Train_error)
    ### ========== TODO : END ========== ###





    ### ========== TODO : START ========== ###
    # part e: use cross-validation to compute average training and test error of classifiers
    print('Investigating various classifiers...')
    error(MajorityVoteClassifier(), X, y, ntrials = 100, test_size = 0.2)                       # calling error() to display all three errors for 4 cases
    error(RandomClassifier(), X, y, ntrials = 100, test_size = 0.2)
    error(DecisionTreeClassifier(criterion='entropy'), X, y, ntrials = 100, test_size = 0.2)
    error(KNeighborsClassifier(n_neighbors = 5), X, y, ntrials = 100, test_size = 0.2)
    ### ========== TODO : END ========== ###





    ### ========== TODO : START ========== ###
    # part f: use 10-fold cross-validation to find the best value of k for k-Nearest Neighbors classifier
    print('Finding the best k...')
    knnPlotX = list(range(1, 51))                                                                                               # initializing a list [1...50]
    knnPlotY = [0] * 50                                                                                                         # empty list of 50 elements to be modified
    for k in range(1, 51):
      knnPlotY[k - 1] = 1 - (cross_val_score(estimator = KNeighborsClassifier(n_neighbors = k), X = X, y = y, cv = 10)).mean()  # for all values of k, calc the cross_val_score
    # plot_histogram(knnPlotX, knnPlotY, 'k', 'validation error')
    plt.figure(1)                                                                                                               # plotting here
    plt.plot(knnPlotX, knnPlotY)
    plt.xlabel('k')
    plt.ylabel('validation error')
    plt.title('k vs validation error')
    plt.xlim(0, 51)
    plt.ylim(0, 1)
    plt.show()
    ### ========== TODO : END ========== ###





    ### ========== TODO : START ========== ###
    # part g: investigate decision tree classifier with various depths
    print('Investigating depths...')
    dtPlotX = list(range(1, 21))                                                                                                # initializing a list [1...20]
    dtPlotY = [0] * 20                                                                                                          # empty list of 20 elements to be modified
    for depth in range(1, 21):                                                                                                  # for all values of k, calc the cross_val_score
      dtPlotY[depth - 1] = 1 - (cross_val_score(estimator = DecisionTreeClassifier(max_depth = depth, criterion='entropy'), X = X, y = y, cv = 10)).mean()
    # plot_histogram(dtPlotX, dtPlotY, 'depth', 'validation error')
    plt.figure(2)                                                                                                               # plotting here
    plt.plot(dtPlotX, dtPlotY)
    plt.xlabel('depth')
    plt.ylabel('validation error')
    plt.title('depth vs validation error')
    plt.xlim(0, 21)
    plt.ylim(0, 1)
    plt.show()
    ### ========== TODO : END ========== ###





    ### ========== TODO : START ========== ###
    # part h: investigate decision tree and k-Nearest Neighbors classifier with various training set sizes
    plotX = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]                                                  # X axis to be plot on
    dtTrainingError = [0] * 10                                                                                  # 4 y-axes for values given by variable names
    dtTestingError = [0] * 10
    knnTrainingError = [0] * 10
    knnTestingError = [0] * 10
    trainIndex = np.random.choice(X.shape[0], int(X.shape[0] * 0.9), replace=False)                             # randomly selecting 9/10 of sample indices without replacement for training cases
    testIndex = np.delete(np.arange(X.shape[0]), trainIndex)                                                    # use remaining indices as test cases
    trainX = X[trainIndex,:]                                                                                    # explicitly get the training and test cases
    trainY = y[trainIndex]
    testX = X[testIndex,:]
    testY = y[testIndex]
    for perc in range(1, 11):                                                                                   # for each increment of 10%
      trainSubsetIndex = np.random.choice(trainX.shape[0], int(trainX.shape[0] * 0.1 * perc), replace=False)    # take a random subset of the training case indices
      trainXSubset = trainX[trainSubsetIndex,:]                                                                 # get the subset from the training cases
      trainYSubset = trainY[trainSubsetIndex]
      dtClassifier = DecisionTreeClassifier(criterion='entropy', max_depth = 5)                                 # trainging the decision tree
      dtClassifier.fit(trainXSubset, trainYSubset)                                                              # 2 predictions for decision tree for training and testing errors (and storing them)
      y_predDT = dtClassifier.predict(trainXSubset)
      dtTrainingError[perc - 1] = 1 - metrics.accuracy_score(trainYSubset, y_predDT, normalize=True)
      y_predDT = dtClassifier.predict(testX)
      dtTestingError[perc - 1] = 1 - metrics.accuracy_score(testY, y_predDT, normalize=True)
      knnClassifier = KNeighborsClassifier(n_neighbors = 5)                                                     # training KNN
      knnClassifier.fit(trainXSubset, trainYSubset)                                                             # 2 predicions for KNN for training and testing errors (and storing them)
      y_predKNN = knnClassifier.predict(trainXSubset)
      knnTrainingError[perc - 1] = 1 - metrics.accuracy_score(trainYSubset, y_predKNN, normalize=True)
      y_predKNN = knnClassifier.predict(testX)
      knnTestingError[perc - 1] = 1 - metrics.accuracy_score(testY, y_predKNN, normalize=True)
    plt.figure(3)                                                                                               # 4 plots for each case
    plt.plot(plotX, dtTrainingError)
    plt.xlabel('subset ratio')
    plt.ylabel('training error')
    plt.title('DT: subset ratio vs training error')
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.show()
    plt.figure(4)
    plt.plot(plotX, dtTestingError)
    plt.xlabel('subset ratio')
    plt.ylabel('testing error')
    plt.title('DT: subset ratio vs testing error')
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.show()
    plt.figure(5)
    plt.plot(plotX, knnTrainingError)
    plt.xlabel('subset ratio')
    plt.ylabel('training error')
    plt.title('KNN: subset ratio vs training error')
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.show()
    plt.figure(6)
    plt.plot(plotX, knnTestingError)
    plt.xlabel('subset ratio')
    plt.ylabel('testing error')
    plt.title('KNN: subset ratio vs testing error')
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.show()
    
    ### ========== TODO : END ========== ###



    print('Done')


if __name__ == "__main__":
    main()
